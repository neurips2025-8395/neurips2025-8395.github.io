<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <link rel="stylesheet" href="main.css">
    <title>Supplementary Materials</title>
</head>

<body>
    <div id="title_slide">
        <div class="title_left">
            <h1>Supplementary Materials</h1>
            <div class="nips">
                <p>NeurIPS 2025 Submission #8395</p>
            </div>
            <br>

            <div id="abstract" class="grid-container">
                <p>
                    This webpage contains the supplementary materials for the NeurIPS 2025 submission #8395. We include
                    videos of our neural network model running on the real robot. All of the videos show autonomous
                    model execution and are in real time at 1x (none of the videos are sped up).
                </p>
            </div>
        </div>
    </div>
    <hr class="rounded">
    <div id="overview">

        <h1>Laundry Folding</h1>
        <p>
            Our model performs long-horizon laundry folding with dynamic and reactive manipulation strategies.
            Our model successfully folds towels across various initial configurations.
        </p>
        <br>
        <div class="allegroupper">
            <video autoplay muted playsinline loop preload="metadata">
                <source src="assets/grid/diag3.mp4" type="video/mp4">
            </video>
            <video autoplay muted playsinline loop preload="metadata">
                <source src="assets/grid/back2.mp4" type="video/mp4">
            </video>
        </div>
        <div class="allegrolower">
            <div class="video_container">
                <video autoplay muted playsinline loop preload="metadata">
                    <source src="assets/grid/backdiag1.mp4" type="video/mp4">
                </video>
                <div class="caption">
                    <p>Long-horizon folding across diverse initial towel configurations.</p>
                </div>
            </div>
            <div class="video_container">
                <video autoplay muted playsinline loop preload="metadata">
                    <source src="assets/grid/side1.mp4" type="video/mp4">
                </video>
            </div>
        </div>

        <h1>Reactive Behaviors</h1>
        <p>
            Predicting the next token at closed-loop 50Hz enables the robot to dynamically recover from failed attempts
            and retry with precisely adjusted motions.

        </p>
        <br>
        <div class="allegrolower">
            <div class="video_container">
                <video autoplay muted playsinline loop preload="metadata">
                    <source src="assets/grid/diag4.mov" type="video/mp4">
                </video>
                <div class="caption">
                    <p>Quick recoveries from failed flinging and picking.</p>
                </div>
            </div>
            <div class="video_container">
                <video autoplay muted playsinline loop preload="metadata">
                    <source src="assets/grid/back1.mp4" type="video/mp4">
                </video>
            </div>
        </div>

        <!-- <h1>Comparison to the State of the Art</h1>
                <p>
                    pi0 comparison
                </p>
                <br>
                <div class="allegrolower">
                    <div class="video_container">
                        <video autoplay muted playsinline loop preload="metadata">
                            <source src="assets/grid/turn-clock.mov" type="video/mp4">
                        </video>
                        <div class="caption">
                            <p>Clockwise (left) and anti-clockwise (right) turning in the real world</p>
                        </div>
                    </div>
                    <div class="video_container">
                        <video autoplay muted playsinline loop preload="metadata">
                            <source src="assets/grid/turn-anticlock.mov" type="video/mp4">
                        </video>
                    </div>
                </div> -->

        <!-- <h1>Longer Context</h1>
        <p>
            We compare the performance of our model with different context lengths.
            We observe that longer context length leads to smoother and more temporally consistent behaviors,
            while shorter context length leads to more shaky and greedy strategies.
        </p>
        <br>
        <div class="allegrolower">
            <div class="video_container">
                <video autoplay muted playsinline loop preload="metadata">
                    <source src="assets/grid/cl16.mp4" type="video/mp4">
                </video>
                <div class="caption">
                    <p>Context length of 16</p>
                </div>
            </div>
            <div class="video_container">
                <video autoplay muted playsinline loop preload="metadata">
                    <source src="assets/grid/cl1.mp4" type="video/mp4">
                </video>
                <div class="caption">
                    <p>Context length of 1</p>
                </div>
            </div>
        </div> -->

        <h1>Emergent Behaviors</h1>
        <p>
            Our neural network exhibits several behaviors that are not present in the training data.
            These include recovering from messy attempts and a 90-degree towel rotation strategy through
            reflinging.
        </p>
        <br>
        <div class="allegrolower">
            <div class="video_container">
                <video autoplay muted playsinline loop preload="metadata">
                    <source src="assets/grid/diag2.mp4" type="video/mp4">
                </video>
                <div class="caption">
                    <p>Recover from novel messy attempts.</p>
                </div>
            </div>
            <div class="video_container">
                <video autoplay muted playsinline loop preload="metadata">
                    <source src="assets/grid/diag1.mp4" type="video/mp4">
                </video>
                <div class="caption">
                    <p>Novel 90 degree rotation of towel via strategic reflinging.</p>
                </div>
            </div>
        </div>

        <h1>Uncut Videos</h1>
        <p>
            Our model can perform a number of successful folds in a row before failure.
            We show an uncut sequence of successful folds followed by failure.
        </p>
        <br>
        <div class="dexteruncut">
            <div class="video_container">
                <video controls autoplay muted playsinline loop preload="metadata">
                    <source src="assets/grid/six.mp4" type="video/mp4">
                </video>
                <div class="caption">
                    <p>Six successful folds in a row followed by timeout failure.</p>
                </div>
            </div>
            <!-- <div class="video_container">
                <video autoplay muted playsinline loop preload="metadata">
                    <source src="assets/grid/turn-anticlock.mov" type="video/mp4">
                </video>
            </div> -->
        </div>




    </div>
    <script type="text/javascript">
        /* https://stackoverflow.com/questions/3027707/how-to-change-the-playing-speed-of-videos-in-html5 */
        document.querySelector('video').defaultPlaybackRate = 1.0;
        document.querySelector('video').play();

        var videos = document.querySelectorAll('video');
        for (var i = 0; i < 1; i++) {
            videos[i].playbackRate = 1.0;
        }
    </script>
    <script>
        /* https://stackoverflow.com/questions/21163756/html5-and-javascript-to-play-videos-only-when-visible */
        var videos = document.getElementsByTagName("video");

        function checkScroll() {
            var fraction = 0.5; // Play when 70% of the player is visible.

            for (var i = 0; i < 1; i++) {  // only apply to the first video

                var video = videos[i];

                var x = video.offsetLeft, y = video.offsetTop, w = video.offsetWidth, h = video.offsetHeight, r = x + w, //right
                    b = y + h, //bottom
                    visibleX, visibleY, visible;

                visibleX = Math.max(0, Math.min(w, window.pageXOffset + window.innerWidth - x, r - window.pageXOffset));
                visibleY = Math.max(0, Math.min(h, window.pageYOffset + window.innerHeight - y, b - window.pageYOffset));

                visible = visibleX * visibleY / (w * h);

                if (visible > fraction) {
                    video.play();
                } else {
                    video.pause();
                }

            }

        }
        window.addEventListener('scroll', checkScroll, false);
        window.addEventListener('resize', checkScroll, false);
    </script>
    <script>
        // Function to check if the user is on a mobile device
        function isMobileDevice() {
            return /Mobi|Android/i.test(navigator.userAgent);
        }

        // If the user is on a mobile device, disable autoplay
        if (isMobileDevice()) {
            const videos = document.querySelectorAll('video');
            videos.forEach(video => {
                video.autoplay = false;
            });
        }
    </script>
    <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=51e0d73d83d06baa7a00000f"
        type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
        crossorigin="anonymous"></script>
    <script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd002feec.js"
        type="text/javascript"></script>
</body>

</html>